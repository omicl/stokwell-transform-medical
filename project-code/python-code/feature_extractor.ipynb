{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"vdHApzB309GA"},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers import Dense, Flatten\n","from keras.layers.convolutional import Conv2D, MaxPooling2D\n","from keras.preprocessing import image\n","from keras.applications.imagenet_utils import preprocess_input\n","from keras.models import Model\n","import numpy as np\n","import pandas as pd\n","from tensorflow.keras.preprocessing import image\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten ,Activation\n","from keras.layers import Conv2D, MaxPooling2D\n","#from keras.preprocessing import image\n","from keras.utils import load_img, img_to_array\n","import os\n","import random\n","\n","\n","# Load the pre-trained AlexNet model\n","model = Sequential()\n","model.add(Conv2D(96, (11,11), strides=(4,4), activation='relu', input_shape=(227,227,3)))\n","model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n","model.add(Conv2D(256, (5,5), strides=(1,1), activation='relu', padding='same'))\n","model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n","model.add(Conv2D(384, (3,3), strides=(1,1), activation='relu', padding='same'))\n","model.add(Conv2D(384, (3,3), strides=(1,1), activation='relu', padding='same'))\n","model.add(Conv2D(256, (3,3), strides=(1,1), activation='relu', padding='same'))\n","model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n","model.add(Flatten())\n","model.add(Dense(4096, activation='relu'))\n","model.add(Dense(2048, activation='relu'))\n","model.add(Dense(1024, activation='relu'))\n","model.add(Dense(1024, activation='relu'))\n","model.add(Dense(512, activation='relu'))\n","model.add(Dense(512, activation='relu'))\n","model.add(Dense(1000, activation='softmax'))\n","#model.load_weights('alexnet_weights.h5')\n","# Remove last layer to get feature extractor\n","feature_extractor = Model(inputs=model.input, outputs=model.layers[-2].output)\n","#df = pd.read_csv('/content/drive/MyDrive/ALL_IMAGES.csv')\n","# Load and preprocess image one by one and extract features\n","model.summary()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G6vMLQ2AO2x_"},"outputs":[],"source":["ID = pd.read_csv('/content/drive/MyDrive/ID.csv')\n","ID2=pd.read_csv('/content/drive/MyDrive/label_data.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ngYR3TCfY741"},"outputs":[],"source":["\n","features_matrix=np.zeros((6144,942,))\n","for i in range(len(ID)): # Change 10 with the number of images in your dataset\n","    file=[]\n","    folder_path = '/content/drive/MyDrive/ALL_IMAGES/'\n","    img_name=ID.ID[i]\n","    # List all the files in the folder\n","    #filenames = os.listdir(folder_path)\n","\n","    # Define the first four characters of the filenames to search for\n","    prefix = str(img_name)\n","\n","    # Filter the list of files based on the prefix\n","    files = [file for file in os.listdir(folder_path) if file.startswith(prefix)]\n","\n","    # Randomly select a specified number of files from the filtered list\n","    num_files = len(files)\n","    selected_files = random.sample(files, num_files)\n","    img=[]\n","    features=[]\n","    # Print the paths to the selected image files\n","    for file in selected_files:\n","        print(\"Selected image file:\", os.path.join(folder_path, file))\n","        img = image.load_img(os.path.join(folder_path, file), target_size=(227, 227))\n","        img = image.img_to_array(img)\n","        img = np.expand_dims(img, axis=0)\n","        img = preprocess_input(img)\n","        feature=feature_extractor.predict(img)\n","        features.append(feature)\n","\n","    feature_vector=np.concatenate(features)\n","    F_vector = feature_vector.reshape(1, -1)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"stOgXoMTaaGU"},"outputs":[],"source":["#همراه با داده های کلینیکال\n","    features_matrix[:, i] = np.concatenate((F_vector.flatten(),ID2[i],np.zeros(features_matrix.shape[0]-(F_vector.shape[1]+ID2.shape[1]))))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g9Sp9vfsoEuf"},"outputs":[],"source":[" #بدون دادهای کلینیکال\n"," features_matrix[:, i] = np.concatenate((F_vector.flatten(),np.zeros(features_matrix.shape[0]-(F_vector.shape[1]))))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1VfJTb9T6Mtn"},"outputs":[],"source":["np.save('/content/drive/MyDrive/features_matrix2.npy', features_matrix)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"mount_file_id":"100YpV7rhRckmJa_rryRl4QGS-MYuADUA","authorship_tag":"ABX9TyOQL/Dq4bAGVF7dgyuylZjf"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}